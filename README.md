# Spark Feature Engineering & Machine Learning

## Overview
This project demonstrates a scalable machine learning pipeline built using PySpark. It focuses on distributed feature engineering, categorical encoding, vector assembly, and model training using Spark ML.

## Key Components
- Data preprocessing at scale
- Categorical feature indexing & encoding
- VectorAssembler pipeline
- Train/test split
- Model training using Spark ML
- Model evaluation

## Technologies Used
- PySpark
- Spark ML
- Python

## Skills Demonstrated
- Distributed data processing
- Large-scale feature engineering
- End-to-end ML pipeline construction
- Model evaluation in Spark

## How to Run
1. Install PySpark:
   pip install pyspark
2. Run:
`spark_ml_pipeline.ipynb`
